<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Gradient Vanishing이란? | Jaylog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Gradient Vanishing Problem(기울기값이 소실)는 인공신경망을 기울기값을 베이스로 하는 method (back propagation)로 학습시키려고 할 때 발생되는 어려움이다. 특히 이 문제는 네트워크에서 앞쪽 레이어의 파라미터들을 학습시키고, 튜닝하기 정말 어렵게 만든다 (Backprop은 뒤에서 앞으로 진행되므로 중간에 기울기가 소실되">
<meta property="og:type" content="article">
<meta property="og:title" content="Gradient Vanishing이란?">
<meta property="og:url" content="http://yoursite.com/2020/08/27/Gradient-Vanishing%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB/index.html">
<meta property="og:site_name" content="Jaylog">
<meta property="og:description" content="Gradient Vanishing Problem(기울기값이 소실)는 인공신경망을 기울기값을 베이스로 하는 method (back propagation)로 학습시키려고 할 때 발생되는 어려움이다. 특히 이 문제는 네트워크에서 앞쪽 레이어의 파라미터들을 학습시키고, 튜닝하기 정말 어렵게 만든다 (Backprop은 뒤에서 앞으로 진행되므로 중간에 기울기가 소실되">
<meta property="og:locale">
<meta property="article:published_time" content="2020-08-27T07:07:41.000Z">
<meta property="article:modified_time" content="2023-01-04T12:24:44.234Z">
<meta property="article:author" content="Jay_Kim">
<meta property="article:tag" content="DeepLearning">
<meta property="article:tag" content="GradientVanishing">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Jaylog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Jaylog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Gradient-Vanishing이란" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/27/Gradient-Vanishing%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB/" class="article-date">
  <time datetime="2020-08-27T07:07:41.000Z" itemprop="datePublished">2020-08-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Gradient Vanishing이란?
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Gradient Vanishing Problem(기울기값이 소실)는 인공신경망을 기울기값을 베이스로 하는 method (back propagation)로 학습시키려고 할 때 발생되는 어려움이다.</p>
<p>특히 이 문제는 네트워크에서 앞쪽 레이어의 파라미터들을 학습시키고, 튜닝하기 정말 어렵게 만든다 (Backprop은 뒤에서 앞으로 진행되므로 중간에 기울기가 소실되면 앞단 layer들의 업데이트가 안된다). 이 문제는 신경망 구조에서 레이어가 늘어날수록 더 악화된다.</p>
<p>이것은 뉴럴 네트워크의 근본적인 문제점이 아니다. 이것은 특정한 activation function를 통해서 기울기 베이스의 학습 method를 사용할 때 문제가 된다.</p>
<p>자 한번 이러한 문제를 직관적으로 이해해보고, 그것으로 인해 야기되는 문제를 짚어보자.</p>
<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>Gradient 기반의 method는 parameter value의 작은 변화가 network output에 얼마나 영향을 미칠지를 이해하는 것을 기반으로 parameter value를 학습시킨다.</p>
<p>만약 parameter value의 변화가 network’s output의 매우 작은 변화를 야기한다면, 네트워크는 parameter를 효과적으로 학습시킬 수 없게 되는데 이것이 문제다.</p>
<p>gradient라는 것이 결국 미분값 즉 변화량을 의미하는데, 이 변화량이 매우 작다면, network 를 효과적으로 학습시키지 못하고, error rate이 미쳐 다 낮아지지 못한채 수렴해버리는 문제가 발생한다는 것 같다.</p>
<p>이 상황이 바로 vanishing gradient problem으로 발생하는 문제인데, 이 문제로 초기 레이어에서 각각의 parameter들에 대한 network’s output의 gradient는 극도로 작아지게 된다. 이걸 좀 근사하게 얘기하면, 초기 레이어에서 parameter value에 대해 큰 변화가 발생해도 output에 대해서 큰 영향을 주지 못한다는 것이다.</p>
<p>그렇다면, 언제, 왜 이러한 문제가 발생하는지 살펴보자.</p>
<h3 id="Cause"><a href="#Cause" class="headerlink" title="Cause"></a>Cause</h3><p>Vanishing gradient problem은 activation function을 선택하는 문제에 의존적으로 일어난다. sigmoid나, tanh 등 요즘 많이들 사용하는 activation function들은 매우 비선형적인 방식으로 그들의 input을 매우 작은 output range로 짓이겨넣는다</p>
<p>예를 들어서, sigmoid는 실수 범위의 수를 [0, 1]로 맵핑한다. 그 결과로 매우 넓은 input space 지역이 극도로 작은 범위로 맵핑되어버린다.</p>
<p>이렇게 되어 버린 input space에서는 큰 변화가 있다고 하더라도, output에는 작은 변화를 보이게 된다. gradient(기울기)가 작기 때문이다.</p>
<p>이러한 현상은 우리가 서로(??)의 꼭대기 층에 그러한 비선형성을 여러개 레이어로 쌓을 때 더욱 악화된다.</p>
<p>예를들어, 첫 레이어에서 넓은 input region을 작은 output region으로 맵핑하고, 그것이 2차 3차 레이어로 갈수록 더 심각하게 작은 region으로 맵핑되는 경우이다.</p>
<p>그 결과로 만약 첫 레이어 input에 대해 매우 큰 변화가 있다고 하더라도 output을 크게 변화시키지 못하게 된다.</p>
<p>우리는 이러한 문제를 해결하기 위해 짓이겨 넣는식(‘squashing’)의 특징을 갖지 않는 activation function을 사용할 수 있다.</p>
<p>ReLU(Rectified Linear Unit - max(0, x))가 잘 선택되는 편이다.</p>
<h3 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h3><ul>
<li><a target="_blank" rel="noopener" href="https://www.quora.com/What-is-the-vanishing-gradient-problem">https://www.quora.com/What-is-the-vanishing-gradient-problem</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/08/27/Gradient-Vanishing%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB/" data-id="clchmzmqu000ciabrhgwl2t1l" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GradientVanishing/" rel="tag">GradientVanishing</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/08/29/Convolution-Layer-%E1%84%80%E1%85%AE%E1%84%92%E1%85%A7%E1%86%AB/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Convolution Layer 구현
        
      </div>
    </a>
  
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/">강화학습</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EA%B3%B5%ED%95%99%EC%88%98%ED%95%99/">공학수학</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EA%B8%80%EC%93%B0%EA%B8%B0/">글쓰기</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EC%8A%A4%ED%83%80%ED%8A%B8%EC%97%85/">스타트업</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EC%9D%BC%EC%83%81/">일상</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BFS/" rel="tag">BFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BellmanEquation/" rel="tag">BellmanEquation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ComputerVision/" rel="tag">ComputerVision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DFS/" rel="tag">DFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dot-Product/" rel="tag">Dot Product</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DynamicProgramming/" rel="tag">DynamicProgramming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GradientVanishing/" rel="tag">GradientVanishing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GridWorld/" rel="tag">GridWorld</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ImageSynthesis/" rel="tag">ImageSynthesis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Inner-Product/" rel="tag">Inner Product</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MDP/" rel="tag">MDP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MonteCarloApproximation/" rel="tag">MonteCarloApproximation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nepal/" rel="tag">Nepal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OptimalAuction/" rel="tag">OptimalAuction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PolicyIteration/" rel="tag">PolicyIteration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PriorityQueue/" rel="tag">PriorityQueue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QFunction/" rel="tag">QFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QLearning/" rel="tag">QLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReinforcementLearning/" rel="tag">ReinforcementLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SARSA/" rel="tag">SARSA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TemporalDifference/" rel="tag">TemporalDifference</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Travel/" rel="tag">Travel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ValueFunction/" rel="tag">ValueFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ValueIteration/" rel="tag">ValueIteration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vector/" rel="tag">Vector</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/heapq/" rel="tag">heapq</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%EC%8B%A4%ED%8C%A8/" rel="tag">실패</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%EC%9D%BC%EC%83%81/" rel="tag">일상</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%ED%9A%8C%EA%B3%A0/" rel="tag">회고</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 13.33px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 10px;">BFS</a> <a href="/tags/BellmanEquation/" style="font-size: 10px;">BellmanEquation</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/ComputerVision/" style="font-size: 10px;">ComputerVision</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/DeepLearning/" style="font-size: 20px;">DeepLearning</a> <a href="/tags/Dot-Product/" style="font-size: 10px;">Dot Product</a> <a href="/tags/DynamicProgramming/" style="font-size: 10px;">DynamicProgramming</a> <a href="/tags/GAN/" style="font-size: 10px;">GAN</a> <a href="/tags/GradientVanishing/" style="font-size: 10px;">GradientVanishing</a> <a href="/tags/GridWorld/" style="font-size: 10px;">GridWorld</a> <a href="/tags/ImageSynthesis/" style="font-size: 10px;">ImageSynthesis</a> <a href="/tags/Inner-Product/" style="font-size: 10px;">Inner Product</a> <a href="/tags/MDP/" style="font-size: 10px;">MDP</a> <a href="/tags/MonteCarloApproximation/" style="font-size: 10px;">MonteCarloApproximation</a> <a href="/tags/Nepal/" style="font-size: 10px;">Nepal</a> <a href="/tags/OptimalAuction/" style="font-size: 10px;">OptimalAuction</a> <a href="/tags/PolicyIteration/" style="font-size: 10px;">PolicyIteration</a> <a href="/tags/PriorityQueue/" style="font-size: 10px;">PriorityQueue</a> <a href="/tags/QFunction/" style="font-size: 10px;">QFunction</a> <a href="/tags/QLearning/" style="font-size: 10px;">QLearning</a> <a href="/tags/ReinforcementLearning/" style="font-size: 16.67px;">ReinforcementLearning</a> <a href="/tags/SARSA/" style="font-size: 10px;">SARSA</a> <a href="/tags/TemporalDifference/" style="font-size: 10px;">TemporalDifference</a> <a href="/tags/Travel/" style="font-size: 10px;">Travel</a> <a href="/tags/ValueFunction/" style="font-size: 10px;">ValueFunction</a> <a href="/tags/ValueIteration/" style="font-size: 10px;">ValueIteration</a> <a href="/tags/Vector/" style="font-size: 10px;">Vector</a> <a href="/tags/heapq/" style="font-size: 10px;">heapq</a> <a href="/tags/%EC%8B%A4%ED%8C%A8/" style="font-size: 10px;">실패</a> <a href="/tags/%EC%9D%BC%EC%83%81/" style="font-size: 10px;">일상</a> <a href="/tags/%ED%9A%8C%EA%B3%A0/" style="font-size: 10px;">회고</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/01/02/2022%EB%85%84-%ED%9A%8C%EA%B3%A0/">2022년 회고, 스타트업 실패에 대하여</a>
          </li>
        
          <li>
            <a href="/2022/12/28/%ED%9E%88%EB%A7%90%EB%9D%BC%EC%95%BC-%ED%99%98%EC%83%81%EB%B0%A9%ED%99%A9%20-%20(1)/">&lt;히말라야 환상방황&gt; - EP 1. 혼돈의 타멜거리</a>
          </li>
        
          <li>
            <a href="/2021/07/19/StarGAN-v2%20%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%20%E1%84%85%E1%85%B5%E1%84%87%E1%85%B2/">StarGAN-v2 논문 리뷰</a>
          </li>
        
          <li>
            <a href="/2021/02/05/Priority-Queue-%E1%84%8B%E1%85%AE%E1%84%89%E1%85%A5%E1%86%AB%E1%84%89%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%B1%E1%84%8F%E1%85%B2/">Priority Queue(우선순위큐)</a>
          </li>
        
          <li>
            <a href="/2021/02/05/DFS%E1%84%8B%E1%85%AABFS/">DFS와 BFS</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Jay_Kim<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>