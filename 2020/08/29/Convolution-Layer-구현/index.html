<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Convolution Layer 구현 | Jaylog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="cs231n assignment2의 Convolution Layer를 구현해보며 느낀점을 정리해보았다.개념보다는 구현에 초점을 맞춘 포스트이므로 참고바람. Convolution LayerCNN의 핵심은 convolution operation 즉, 합성곱 연산이다. 기존의 Fully Connected Layer와 다른 Convolution Layer의 특징은">
<meta property="og:type" content="article">
<meta property="og:title" content="Convolution Layer 구현">
<meta property="og:url" content="http://yoursite.com/2020/08/29/Convolution-Layer-%E1%84%80%E1%85%AE%E1%84%92%E1%85%A7%E1%86%AB/index.html">
<meta property="og:site_name" content="Jaylog">
<meta property="og:description" content="cs231n assignment2의 Convolution Layer를 구현해보며 느낀점을 정리해보았다.개념보다는 구현에 초점을 맞춘 포스트이므로 참고바람. Convolution LayerCNN의 핵심은 convolution operation 즉, 합성곱 연산이다. 기존의 Fully Connected Layer와 다른 Convolution Layer의 특징은">
<meta property="og:locale">
<meta property="og:image" content="http://yoursite.com/image/post_image/20200829/conv_layer1.png">
<meta property="og:image" content="http://yoursite.com/image/post_image/20200829/conv_layer2.png">
<meta property="og:image" content="http://yoursite.com/image/post_image/20200829/Conv_forward.jpeg">
<meta property="og:image" content="http://yoursite.com/image/post_image/20200829/conv_layer3.png">
<meta property="article:published_time" content="2020-08-29T06:40:48.000Z">
<meta property="article:modified_time" content="2023-01-04T12:24:44.238Z">
<meta property="article:author" content="Jay_Kim">
<meta property="article:tag" content="CNN">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/image/post_image/20200829/conv_layer1.png">
  
    <link rel="alternate" href="/atom.xml" title="Jaylog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Jaylog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Convolution-Layer-구현" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/29/Convolution-Layer-%E1%84%80%E1%85%AE%E1%84%92%E1%85%A7%E1%86%AB/" class="article-date">
  <time datetime="2020-08-29T06:40:48.000Z" itemprop="datePublished">2020-08-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Convolution Layer 구현
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>cs231n assignment2의 <code>Convolution Layer</code>를 구현해보며 느낀점을 정리해보았다.<br>개념보다는 구현에 초점을 맞춘 포스트이므로 참고바람.</p>
<h3 id="Convolution-Layer"><a href="#Convolution-Layer" class="headerlink" title="Convolution Layer"></a>Convolution Layer</h3><p>CNN의 핵심은 convolution operation 즉, 합성곱 연산이다. 기존의 Fully Connected Layer와 다른 Convolution Layer의 특징은 Input의 Spatial Structure, 공간적 구조를 보존한다는 것이다. Convolution 연산을 수행하면 input에 대한 feature map을 뽑을 수 있는데,</p>
<div class="image-box">
                <img src="/image/post_image/20200829/conv_layer1.png" style="요로코롬1" alt="" title="" class="">
                <p class="image-box-title"></p>
            </div>
<div class="image-box">
                <img src="/image/post_image/20200829/conv_layer2.png" style="요로코롬2" alt="" title="" class="">
                <p class="image-box-title"></p>
            </div>

<p>filter의 개수에 따라 output인 activation map의 depth가 달라지며, filter가 어떤식으로 input을 sliding 하는지에 따라 activation map의 size가 변화한다. input_size(N), filter_size(F), padding(p) 등의 조건이 있다면 다음의 식으로 간단하게 Output size를 알아낼 수 있다.</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="24.6ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10873.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(1499.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2499.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(2999.4,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(3724.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(4724.9,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mo" transform="translate(5473.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(5862.9,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(6362.9,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(7007.9,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(7368.9,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7819.9,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(8164.9,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(8684.9,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(9373.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(10373.3,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></p>
<p>그럼 정리해보자면,<br>Convolution layer란 녀석은 input을 각 필터로 sliding하면서 값을 계산하기만 하면 되는 짜기 easy한 녀석이 아닐까?</p>
<p>맞긴한데 짜면서 아주 호되게 혼났다.</p>
<h3 id="Forward-Pass"><a href="#Forward-Pass" class="headerlink" title="Forward Pass"></a>Forward Pass</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">conv_forward_naive</span>(<span class="params">x, w, b, conv_param</span>):</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Input:</span></span><br><span class="line"><span class="string">- x: Input data of shape (N, C, H, W)</span></span><br><span class="line"><span class="string">- w: Filter weights of shape (F, C, HH, WW)</span></span><br><span class="line"><span class="string">- b: Biases, of shape (F,)</span></span><br><span class="line"><span class="string">- conv_param: A dictionary with the following keys:</span></span><br><span class="line"><span class="string">	- 'stride': The number of pixels between adjacent receptive fields in the horizontal and vertical directions.</span></span><br><span class="line"><span class="string">	- 'pad': The number of pixels that will be used to zero-pad the input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns a tuple of:</span></span><br><span class="line"><span class="string">- out: Output data, of shape (N, F, H', W') where H' and W' are given by</span></span><br><span class="line"><span class="string">	H' = 1 + (H + 2 * pad - HH) / stride</span></span><br><span class="line"><span class="string">	W' = 1 + (W + 2 * pad - WW) / stride</span></span><br><span class="line"><span class="string">- cache: (x, w, b, conv_param)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">out = <span class="literal">None</span></span><br><span class="line">cache = (x, w, b, conv_param)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure>

<p>문제를 조금 해석해보자면,</p>
<ol>
<li>size가 H x W x C(channel의 수, rgb 같은) 인 이미지 N개가 input x로 들어왔다.</li>
<li>input을 size가 HH x WW x C인 필터 F개로 sliding 하고,</li>
<li>size가 F인 bias도 더해서,</li>
<li>size가 H’x W’x F인 out N개로 만들어내라.</li>
<li>이때 H’, W’은 위에서 살펴보았던 식으로 잘 계산해라</li>
</ol>
<p>요런 문제이다.<br>그럼 computation graph를 한번 생각해보자.</p>
<div class="image-box">
                <img src="/image/post_image/20200829/Conv_forward.jpeg" style="computational graph" alt="" title="" class="">
                <p class="image-box-title"></p>
            </div>

<p>다이렉트로 out이 나오는 그래프는 아니다.<br>먼저 input x에 padding을 추가해주고, filter의 크기만큼을 crop한 뒤, filter와 내적을 취해주고, bias term을 더해주는 과정이다.<br>이 과정을 거치고 나면 (N,F)의 spatial_out이 계산되는 데,</p>
<div class="image-box">
                <img src="/image/post_image/20200829/conv_layer3.png" style="spatial_out 생김새" alt="" title="" class="">
                <p class="image-box-title"></p>
            </div>

<p>요 그림에서 가운데 공이 담긴 녀석(공이 각각의 필터가 계산한 값이고, F개 있다고 보면 됨)이 N개 있는 꼴이라고 생각하면 된다.</p>
<p>이 과정을 H’xW’ 번 해주면 우리가 원하는 out(N,F,H’,W’)을 얻어낼 수 있는 것이다!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">N, C, H, W = x.shape</span><br><span class="line">F, C, HH, WW = w.shape</span><br><span class="line"></span><br><span class="line">stride = conv_param[<span class="string">'stride'</span>]</span><br><span class="line">pad = conv_param[<span class="string">'pad'</span>]</span><br><span class="line"></span><br><span class="line">npad = ((<span class="number">0</span>,<span class="number">0</span>),  (<span class="number">0</span>,<span class="number">0</span>),  (pad,pad),  (pad,pad)) <span class="comment"># padding 위한 값</span></span><br><span class="line">filter_size = C*HH*WW <span class="comment"># 내적의 용이성을 위해 미리 계산해두는 값</span></span><br><span class="line"></span><br><span class="line">H_out = <span class="built_in">int</span>(<span class="number">1</span> + (H + <span class="number">2</span> * pad - HH) / stride) <span class="comment"># H'</span></span><br><span class="line">W_out = <span class="built_in">int</span>(<span class="number">1</span> + (W + <span class="number">2</span> * pad - WW) / stride) <span class="comment"># W'</span></span><br><span class="line"></span><br><span class="line">out = np.zeros((N, F, H_out, W_out)) <span class="comment"># 최종적으로 구할 out 초기화 (N, F, H', W')</span></span><br><span class="line">x_pad = np.pad(x, npad,  <span class="string">'constant'</span>, constant_values=(<span class="number">0</span>)) <span class="comment"># x에 pad 크기만큼 zero-padding</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> height <span class="keyword">in</span>  <span class="built_in">range</span>(H_out):</span><br><span class="line">	<span class="keyword">for</span> width <span class="keyword">in</span>  <span class="built_in">range</span>(W_out):</span><br><span class="line">		x_crop = x_pad[np.arange(N),  :, height*stride:height*stride+HH, width*stride:width*stride+WW]  <span class="comment"># x에서 (N,C,HH,WW)크기만큼을 crop</span></span><br><span class="line">		x_crop_stretch = x_crop.reshape(N, filter_size)  <span class="comment"># (N, filter_size)</span></span><br><span class="line">		w_stretch = w.reshape(F, filter_size)  <span class="comment"># (F, filter_size)</span></span><br><span class="line">		spatial_out = np.dot(x_crop_stretch, w_stretch.T) + b.reshape((<span class="number">1</span>,F)) <span class="comment"># (N,F)</span></span><br><span class="line">		out[np.arange(N),  :, height, width] = spatial_out</span><br></pre></td></tr></table></figure>

<h3 id="Backward-Pass"><a href="#Backward-Pass" class="headerlink" title="Backward Pass"></a>Backward Pass</h3><p>포워드 열심히 짰으니 이젠 backward 짤 차례다.<br>쫄면 안된다. (이자는 쫄았다)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">conv_backward_naive</span>(<span class="params">dout, cache</span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dout: Upstream derivatives.</span></span><br><span class="line"><span class="string">    - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient with respect to x</span></span><br><span class="line"><span class="string">    - dw: Gradient with respect to w</span></span><br><span class="line"><span class="string">    - db: Gradient with respect to b</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dw, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> dx, dw, db</span><br></pre></td></tr></table></figure>

<p>문제는 참 심플하다.<br>아까 그려놓은 computational graph보면서 dx, dw, db를 구하면 된다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">x, w, b, conv_param = cache</span><br><span class="line">N, C, H, W = x.shape</span><br><span class="line">F, C, HH, WW = w.shape</span><br><span class="line">N, F, H_out, W_out = dout.shape</span><br><span class="line"></span><br><span class="line">stride = conv_param[<span class="string">'stride'</span>]</span><br><span class="line">pad = conv_param[<span class="string">'pad'</span>]</span><br><span class="line"></span><br><span class="line">npad = ((<span class="number">0</span>,<span class="number">0</span>), (<span class="number">0</span>,<span class="number">0</span>), (pad,pad), (pad,pad)) <span class="comment"># x = (N, C, H+2*pad, W+2*pad)</span></span><br><span class="line">filter_size = C*HH*WW <span class="comment"># scalar, for stretch</span></span><br><span class="line">x_pad = np.pad(x, npad, <span class="string">'constant'</span>, constant_values=(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">dx_pad = np.zeros((N,C,H+<span class="number">2</span>*pad,W+<span class="number">2</span>*pad))</span><br><span class="line">dw = np.zeros((F,C,HH,WW))</span><br><span class="line">db = np.zeros(F)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> height <span class="keyword">in</span> <span class="built_in">range</span>(H_out):</span><br><span class="line">	<span class="keyword">for</span> width <span class="keyword">in</span> <span class="built_in">range</span>(W_out):</span><br><span class="line">		dspatial_out = dout[np.arange(N), :, height, width] <span class="comment"># (N, F)</span></span><br><span class="line">		db += np.<span class="built_in">sum</span>(dspatial_out, axis=<span class="number">0</span>) <span class="comment"># (F, )</span></span><br><span class="line"></span><br><span class="line">		x_tmp = x_pad[np.arange(N), :, height*stride:height*stride+HH, width*stride:width*stride+WW] <span class="comment"># (N, C, HH, WW)</span></span><br><span class="line">		dw_stretch = np.dot(dspatial_out.T, x_tmp.reshape(N, filter_size)) <span class="comment"># (N,F).T @ (N,filter_size) = (F, filter_size)</span></span><br><span class="line">		dw += dw_stretch.reshape(F,C,HH,WW)</span><br><span class="line"></span><br><span class="line">		w_stretch = w.reshape(F, filter_size) <span class="comment"># (F, filter_size)</span></span><br><span class="line">		dx_tmp_stretch = np.dot(dspatial_out, w_stretch) <span class="comment"># (N,F) @ (F,filter_size) = (N, filter_size)</span></span><br><span class="line">		dx_tmp = dx_tmp_stretch.reshape(N,C,HH,WW)</span><br><span class="line">		dx_pad[np.arange(N), :, height*stride:height*stride+HH, width*stride:width*stride+WW] += dx_tmp</span><br><span class="line"></span><br><span class="line">dx = dx_pad[np.arange(N), :, pad:H+pad, pad:W+pad] <span class="comment"># padding 제거한 값</span></span><br></pre></td></tr></table></figure>

<p>간략히 설명하자면,</p>
<p>spatial_out을 구해서 전체 out을 만들어 냈던 것처럼, dout에서 dspatial_out(N,F)을 crop하여 gradient를 계산해 나간다. 주의해야 할 것은 padding된 x값을 이용해 만들어 낸 out 이었기 때문에, dx_pad에 gradient를 계산해 놓고, padding을 제거한 값을 dx에 할당해야 한다는 것이다.</p>
<p>backward 그래프도 그렸으나, 너무 지저분해서 올리진 않겠다..<br>(아이패드 갖고 싶습니다…)</p>
<h3 id="느낀점"><a href="#느낀점" class="headerlink" title="느낀점"></a>느낀점</h3><blockquote>
<p>4중 for문 돌릴 뻔했다.</p>
</blockquote>
<p>무엇을 기준으로 sliding 해나갈지가 너무 애매해서 일단 N, F, H, W 모두 돌렸다.근데 그렇게 한번 짜고나니, N, F에 대해서는 Vectorize의 가능성이 보였고, 짰고, 돌아갔다. 짜릿하더라. 뭐 요정도 일 것 같다.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/08/29/Convolution-Layer-%E1%84%80%E1%85%AE%E1%84%92%E1%85%A7%E1%86%AB/" data-id="clchnc9i20007ddbr8cjwah37" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/09/04/Dot-Product-%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Dot Product 정리
        
      </div>
    </a>
  
  
    <a href="/2020/08/27/Gradient-Vanishing%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Gradient Vanishing이란?</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/">강화학습</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EA%B3%B5%ED%95%99%EC%88%98%ED%95%99/">공학수학</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EA%B8%80%EC%93%B0%EA%B8%B0/">글쓰기</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EC%8A%A4%ED%83%80%ED%8A%B8%EC%97%85/">스타트업</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%EC%9D%BC%EC%83%81/">일상</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BFS/" rel="tag">BFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BellmanEquation/" rel="tag">BellmanEquation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ComputerVision/" rel="tag">ComputerVision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DFS/" rel="tag">DFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dot-Product/" rel="tag">Dot Product</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DynamicProgramming/" rel="tag">DynamicProgramming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GradientVanishing/" rel="tag">GradientVanishing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GridWorld/" rel="tag">GridWorld</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ImageSynthesis/" rel="tag">ImageSynthesis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Inner-Product/" rel="tag">Inner Product</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MDP/" rel="tag">MDP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MonteCarloApproximation/" rel="tag">MonteCarloApproximation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nepal/" rel="tag">Nepal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OptimalAuction/" rel="tag">OptimalAuction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PolicyIteration/" rel="tag">PolicyIteration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PriorityQueue/" rel="tag">PriorityQueue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QFunction/" rel="tag">QFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QLearning/" rel="tag">QLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReinforcementLearning/" rel="tag">ReinforcementLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SARSA/" rel="tag">SARSA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TemporalDifference/" rel="tag">TemporalDifference</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Travel/" rel="tag">Travel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ValueFunction/" rel="tag">ValueFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ValueIteration/" rel="tag">ValueIteration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vector/" rel="tag">Vector</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/heapq/" rel="tag">heapq</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%EC%8B%A4%ED%8C%A8/" rel="tag">실패</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%EC%9D%BC%EC%83%81/" rel="tag">일상</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%ED%9A%8C%EA%B3%A0/" rel="tag">회고</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 13.33px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 10px;">BFS</a> <a href="/tags/BellmanEquation/" style="font-size: 10px;">BellmanEquation</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/ComputerVision/" style="font-size: 10px;">ComputerVision</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/DeepLearning/" style="font-size: 20px;">DeepLearning</a> <a href="/tags/Dot-Product/" style="font-size: 10px;">Dot Product</a> <a href="/tags/DynamicProgramming/" style="font-size: 10px;">DynamicProgramming</a> <a href="/tags/GAN/" style="font-size: 10px;">GAN</a> <a href="/tags/GradientVanishing/" style="font-size: 10px;">GradientVanishing</a> <a href="/tags/GridWorld/" style="font-size: 10px;">GridWorld</a> <a href="/tags/ImageSynthesis/" style="font-size: 10px;">ImageSynthesis</a> <a href="/tags/Inner-Product/" style="font-size: 10px;">Inner Product</a> <a href="/tags/MDP/" style="font-size: 10px;">MDP</a> <a href="/tags/MonteCarloApproximation/" style="font-size: 10px;">MonteCarloApproximation</a> <a href="/tags/Nepal/" style="font-size: 10px;">Nepal</a> <a href="/tags/OptimalAuction/" style="font-size: 10px;">OptimalAuction</a> <a href="/tags/PolicyIteration/" style="font-size: 10px;">PolicyIteration</a> <a href="/tags/PriorityQueue/" style="font-size: 10px;">PriorityQueue</a> <a href="/tags/QFunction/" style="font-size: 10px;">QFunction</a> <a href="/tags/QLearning/" style="font-size: 10px;">QLearning</a> <a href="/tags/ReinforcementLearning/" style="font-size: 16.67px;">ReinforcementLearning</a> <a href="/tags/SARSA/" style="font-size: 10px;">SARSA</a> <a href="/tags/TemporalDifference/" style="font-size: 10px;">TemporalDifference</a> <a href="/tags/Travel/" style="font-size: 10px;">Travel</a> <a href="/tags/ValueFunction/" style="font-size: 10px;">ValueFunction</a> <a href="/tags/ValueIteration/" style="font-size: 10px;">ValueIteration</a> <a href="/tags/Vector/" style="font-size: 10px;">Vector</a> <a href="/tags/heapq/" style="font-size: 10px;">heapq</a> <a href="/tags/%EC%8B%A4%ED%8C%A8/" style="font-size: 10px;">실패</a> <a href="/tags/%EC%9D%BC%EC%83%81/" style="font-size: 10px;">일상</a> <a href="/tags/%ED%9A%8C%EA%B3%A0/" style="font-size: 10px;">회고</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/01/02/2022%EB%85%84-%ED%9A%8C%EA%B3%A0/">2022년 회고, 스타트업 실패에 대하여</a>
          </li>
        
          <li>
            <a href="/2022/12/28/%ED%9E%88%EB%A7%90%EB%9D%BC%EC%95%BC-%ED%99%98%EC%83%81%EB%B0%A9%ED%99%A9%20-%20(1)/">&lt;히말라야 환상방황&gt; - EP 1. 혼돈의 타멜거리</a>
          </li>
        
          <li>
            <a href="/2021/07/19/StarGAN-v2%20%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%20%E1%84%85%E1%85%B5%E1%84%87%E1%85%B2/">StarGAN-v2 논문 리뷰</a>
          </li>
        
          <li>
            <a href="/2021/02/05/Priority-Queue-%E1%84%8B%E1%85%AE%E1%84%89%E1%85%A5%E1%86%AB%E1%84%89%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%B1%E1%84%8F%E1%85%B2/">Priority Queue(우선순위큐)</a>
          </li>
        
          <li>
            <a href="/2021/02/05/DFS%E1%84%8B%E1%85%AABFS/">DFS와 BFS</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Jay_Kim<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>